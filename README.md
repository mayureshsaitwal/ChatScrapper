# ğŸ§  ChatScraper

| Chat UI |
|---------|
| ![Main](assets/main.jpg) 

---

## ğŸ“ Project Overview

**ChatScraper** is a **Streamlit-based chatbot** that leverages **AI-driven content extraction** and **retrieval-augmented generation (RAG)**. It crawls websites using `crawl4ai` and schema-based LLMs to extract meaningful content, embeds it using `Ollama`, and stores it in **ChromaDB**. Users can then ask questions via a conversational UI and get contextually relevant answers.

---

## â­ Features

- LLM-powered content scraping from URLs using `crawl4ai`
- Text extraction via HTML heuristics or schema-based instructions
- Markdown conversion and cleaning for vectorization
- Document chunking and semantic embeddings with `LangChain` + `Ollama`
- Chroma-based vector database for persistence
- Streamlit UI for asking natural language questions

---

## ğŸ’» Installation

```bash
git clone https://github.com/mayureshsaitwal/ChatScrapper.git
cd ChatScraper
```

### (Optional) Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Running the App

### Step 1: Scrape and Embed Data

```bash
python server.py
```

This script loads HTML and metadata from `./data/html` and `./data/metadata`, processes and embeds them.

### Step 2: Launch the Streamlit Frontend

```bash
streamlit run frontend.py
```

You can now interact with the AI chatbot in your browser.

---

## ğŸ“š Key Components

| Component     | Description |
|---------------|-------------|
| `crawl4ai`    | Intelligent headless web crawler |
| `Ollama`      | Local LLM and embedding model runner |
| `LangChain`   | Conversational retrieval and chaining framework |
| `ChromaDB`    | Local vector database |
| `Streamlit`   | UI for chat interaction |

---

## ğŸ“ Project Structure

```
ChatScraper
â”œâ”€â”€ chat.py                 # Simple LLM call via LiteLLM
â”œâ”€â”€ content.py              # HTML content scraper and saver
â”œâ”€â”€ llm.py                  # Schema-based LLM extraction
â”œâ”€â”€ frontend.py             # Streamlit interface
â”œâ”€â”€ server.py               # Vector embedding and storage
â”œâ”€â”€ prompt.py               # Custom AI response prompt
â”œâ”€â”€ instruction.py          # LLM instructions for extraction
â”œâ”€â”€ urls.txt                # URLs to scrape
â”œâ”€â”€ result.txt              # Scraped site links (from sitemap)
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ data/
    â”œâ”€â”€ html/               # Cleaned HTML files
    â”œâ”€â”€ metadata/           # JSON metadata for pages
    â””â”€â”€ chroma/             # Vector store (generated)
```

---

## âš™ï¸ How It Works

1. **Scraping**: Uses either standard or schema-based LLM strategies to extract page content.
2. **Cleaning & Chunking**: Processes raw text with `MarkdownTextSplitter`.
3. **Embedding**: Uses Ollama embeddings (`nomic-embed-text`) for vectorization.
4. **Storage**: Saves to ChromaDB for future semantic search.
5. **Querying**: Questions submitted via Streamlit are processed using LangChain's RAG pipeline.
6. **Answering**: The AI responds with a relevant, context-aware message.

---

## ğŸ’¡ Room for Improvement

- Add ability to input new URLs directly from UI
- Switch between models dynamically (mistral, llama3, etc.)
- Extend to PDF and document scraping
- Add download/export of chat logs

---

## ğŸš¨ Common Errors

- **Model not running**: Start Ollama at `http://localhost:11434`
- **File/path errors**: Ensure your `data/` directory exists
- **Tensor errors**: Use Python â‰¤ 3.10 if using TensorFlow in future extensions

---

## ğŸ‘¥ Contributors

- **You** â€“ Core Developer & Architect

---

## ğŸ“„ License

This project is under the **MIT License**. Free for personal or commercial use.

